# Title and Author

- **Project Title**: Text Classifier using CNN
- **Prepared for UMBC Data Science Master Degree Capstone by**: Dr. Chaojie (Jay) Wang
- **Author**: Srisailam Basanthpur (Fall 2023)
- **Link to the author's GitHub profile**: [GitHub Profile](https://github.com/sribasanth123)
- **Link to the author's LinkedIn profile**: [LinkedIn Profile](https://www.linkedin.com/in/srisailam-basanthpur-687390184/)
- **Link to YouTube Recorded Video**: [https://www.youtube.com/watch?v=ZvIZwENAY-M](https://www.youtube.com/watch?v=ZvIZwENAY-M)

- **Link to power point presentation file** [PPT](Text%20Classification%20CNN.pptx)
# Background

So far, Convolution Neural Networks (CNN) are usually used for image processing. In this study, we aim to analyze if CNN can also be used for processing text.

# Research Question

Convolution Neural Networks are usually used for image processing. So, for this study, we want to investigate whether CNN can be effectively applied to text processing.

# Data

- The data is provided in the form of text files and does not contain any tabular format data.
- The dataset consists of approximately 20,000 newsgroup documents from 20 different newsgroups, with a total size of approximately 46 MB.
- Source: [Dataset Source](https://archive.ics.uci.edu/dataset/113/twenty+newsgroups)
- Data Size: 46MB
- Data Shape (Number of Rows and Columns): It does not follow a traditional tabular structure; instead, data is present in the form of text files (.txt format).
- The data represents different news articles.
- Text documents serve as the input variables, and the target variables are the class labels (Name of the class group).

## Progress as of 6th Oct 2023

1. There are 19,997 documents in the dataset in the form of text files. These documents are grouped into 20 newsgroups. They are:

   - alt.atheism
   - comp.graphics
   - comp.os.ms-windows.misc
   - comp.sys.ibm.pc.hardware
   - comp.sys.mac.hardware
   - comp.windows.x
   - misc.forsale
   - rec.autos
   - rec.motorcycles
   - rec.sport.baseball
   - rec.sport.hockey
   - sci.crypt
   - sci.electronics
   - sci.med
   - sci.space
   - soc.religion.christian
   - talk.politics.guns
   - talk.politics.mideast
   - talk.politics.misc
   - talk.religion.misc

2. The data is distributed almost equally among all the newsgroups.

3. The data is then cleaned using python regular expressions.

4. As part of cleaning, 3 functions have been created.

5. The first function is email processing which takes text as the input in string format and processes the words with email extensions and returns a string which is concatenated with a list of such words.

6. The second function is subject processing which takes text as the input and processes the text line after the word “Subject” and returns the string.

7. The third function is text processing which takes text as the input and performs a series of operations to remove all the unwanted characters and returns the string.

8. These functions are then applied to the documents, and outputs are stored in separate lists.

9. The data frame is created with the above lists and then stored in a pickle file.

10. The email, subject, and text data are concatenated and stored into a single variable as a dependent variable.

11. All the target labels are stored in an independent variable.

12. The data is then split into train and test in the ratio of 75%:25%.

13. The target labels are encoded using label encoder and are then converted to one-hot encoded representation.

14. The train and test datasets are vectorized using Tokenizer and are then padded.

15. Glove vectors of 100 dimensions have been used.

16. An embedding matrix is formed for all the words in the Tokenizer using glove vectors.

17. The model is then built using TensorFlow.

Plotting a graph between Class labels and the count on Number of documents
From the above bar chart it is clear that

All the class labels has equal number of documents except for the soc.religion.christian class label.
</br>
soc.religion.christian class label has 997 documents while all the other class labels have 1000 documents.
</br>
We can say that the dataset is almost balanced one.
</br>
</br>
![Alt text](../Assets/Image1.png)
</br>
</br>
</br>
</br>
**Line chart showing the mean file size of each newsgroup**
</br>
</br>
![Alt text](../Assets/Image2.png)
</br>
</br>
**Observations:**
</br>
From the above line chart it can be observed that the
</br>
talk.religion.misc has got the highest mean file size.</br>
soc.religion.christian has got the lowest mean file size.
</br>
</br>
</br>
**Data Cleaning**
</br>
created a dataframe out of email, subject, text and dir_labels lists
</br>
</br>
![Alt text](../Assets/Image4.png)
</br>
</br>
</br>
extracted the length of the words for each row in the text and assigned new column by name text_word_count.
</br>
</br>
![Alt text](../Assets/Image5.png)
</br>
</br>
</br>
**Distribution of word count in text column**
</br>
</br>
![Alt text](../Assets/Image6.png)
</br>
</br>
Most of the word counts in the text column are less than 1000.
</br>
</br>
</br>
Displaying Word cloud for Text column of the dataset
</br>
</br>
![Alt text](../Assets/Image7.png)
</br>
**Observation:** Ohio state is highly used word in the news article. News articles must have covered most of its news from Ohio state.
</br>
</br>
</br>
Displaying word cloud for subject column
</br>
</br>
![Alt text](../Assets/Image8.png)
</br>
</br>
**Observation:** From the above word cloud, It can be observed that the sale and year are highly used words in the subject of news articles.
</br>
</br>
</br>
**CNN ARCHITECTURE**
</br>
</br>
![Alt text](../Assets/Image9.png)
</br>
</br>
</br>
**CNN Model Performance**
</br>
Train and Test Accuracies of 95% and 93% Without Overfitting
</br>
</br>

![Alt text](../Assets/Image10.png)
</br>
</br>
</br>
**Comparision between Machine Learning Algorithms and CNN Accuracies**

</br>

![Alt text](../Assets/Image11.png)

</br>

**Conclusion:**
</br>
We can Conclude that the CNN has outperformed both logistic regression and Random Forest in terms of accuracies.
</br>
</br>
</br>

**Future Scope**
</br>

**Multilingual Text Classification:**

Extend text classification models to work across multiple languages, addressing challenges related to language-specific nuances and variations.
